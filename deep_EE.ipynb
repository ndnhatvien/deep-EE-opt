{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNnCr9x/Yh1BzaNTRcE5s1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndnhatvien/deep-EE-opt/blob/master/deep_EE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1fYO7DU-lom"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# Copyright (C) 2018-2020 Bho Matthiesen, Karl-Ludwig Besser\n",
        "#\n",
        "# This program is used in the article:\n",
        "#\n",
        "# Bho Matthiesen, Alessio Zappone, Karl-L. Besser, Eduard A. Jorswieck, and\n",
        "# Merouane Debbah, \"A Globally Optimal Energy-Efficient Power Control Framework\n",
        "# and its Efficient Implementation in Wireless Interference Networks,\"\n",
        "# submitted to IEEE Transactions on Signal Processing\n",
        "#\n",
        "# License:\n",
        "# This program is licensed under the GPLv2 license. If you in any way use this\n",
        "# code for research that results in publications, please cite our original\n",
        "# article listed above.\n",
        "#\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools as it\n",
        "import h5py\n",
        "import os\n",
        "import os.path\n",
        "import resource\n",
        "import timeit\n",
        "\n",
        "class IndexPermutationLayer(keras.layers.Layer):\n",
        "    def __init__(self, permutations=None, **kwargs):\n",
        "        if permutations is None:\n",
        "            permutations = list(it.permutations(range(DIM)))\n",
        "        self.permutations = K.constant(permutations, 'int32')\n",
        "        self.num_perms, self.num_ue = np.shape(permutations)\n",
        "        self.perm = 0\n",
        "        super(IndexPermutationLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        def permute_users():\n",
        "            _perm = K.random_uniform((1,), 0, self.num_perms, dtype='int32')\n",
        "            perm = self.permutations[_perm[0], :]\n",
        "            self.perm = perm\n",
        "            t = K.tile(perm, self.num_ue)\n",
        "            r = K.repeat_elements(perm, self.num_ue, 0)\n",
        "            perm_idx = self.num_ue*r + t\n",
        "            self.perm_idx = K.concatenate((perm_idx, K.constant([self.num_ue**2], 'int32')))\n",
        "            P = tf.gather(x, self.perm_idx, axis=-1)\n",
        "            return P\n",
        "        return K.in_train_phase(permute_users, x, training=training)\n",
        "\n",
        "def perm_loss(y_true, y_pred, model=None, layer_name='perm_layer', loss_func=keras.losses.mse):\n",
        "    #training = K.learning_phase()\n",
        "    #if training == 1 or training is True:\n",
        "    #    _perm = model.get_layer(layer_name).perm#_idx\n",
        "    #    y_true = tf.gather(y_true, _perm, axis=-1)\n",
        "    _perm = model.get_layer(layer_name).perm#_idx\n",
        "    y_true = tf.gather(y_true, _perm, axis=-1)\n",
        "    return loss_func(y_true, y_pred)\n",
        "\n",
        "def rel_mse(x_true, x_pred):\n",
        "    loss = K.square(K.abs((x_true - x_pred)/ x_true))\n",
        "    return K.mean(loss, axis=-1)\n",
        "\n",
        "DIM = 4\n",
        "mu = 4\n",
        "Pc = 1\n",
        "\n",
        "def calcObjective(tensors):\n",
        "    h = keras.layers.Reshape((DIM,DIM))(tensors[0][:,:-1])\n",
        "    mmu = mu * tensors[0][:,-1]\n",
        "    x = keras.layers.Activation('relu')(tensors[1])\n",
        "\n",
        "    o = keras.layers.multiply([h,x])\n",
        "    alpha = tf.matrix_diag_part(o)\n",
        "    beta = 1 + (K.sum(o, axis=-1) - alpha)\n",
        "\n",
        "    rate = K.log(1 + alpha/beta)\n",
        "    ret = K.sum(rate / (keras.layers.multiply([mmu, x]) + Pc), axis=-1)\n",
        "    #ret = tf.Print(ret, [ret])\n",
        "    #ret = K.sum(rate, axis=-1)\n",
        "    return ret\n",
        "\n",
        "def calcObjectivePow(tensors):\n",
        "    ten = tf.constant(10, dtype=tensors[0].dtype)\n",
        "\n",
        "    h = tf.pow(ten, tensors[0])\n",
        "    x = tf.pow(ten, tensors[1])\n",
        "\n",
        "    return calcObjective([h, x])\n",
        "\n",
        "def createModel(layer, trainOnObj, sumOutputLayer = False):\n",
        "    from dl import calcObjective, calcObjectivePow, rel_mse\n",
        "\n",
        "    inlayer = keras.layers.Input(shape = (DIM**2+1,))\n",
        "\n",
        "    x = inlayer\n",
        "    __permutations = list(it.permutations(range(DIM)))\n",
        "    x = IndexPermutationLayer(__permutations, name=\"perm_layer\")(x)\n",
        "    for n, a in zip(*layer):\n",
        "        x = keras.layers.Dense(n, activation = a)(x)\n",
        "    predPower = keras.layers.Dense(DIM, activation = 'linear')(x)\n",
        "\n",
        "    assert(not (trainOnObj and sumOutputLayer))\n",
        "\n",
        "    if trainOnObj:\n",
        "        objlayer = keras.layers.Lambda(calcObjectivePow, (1,))([inlayer, predPower])\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = objlayer)\n",
        "    elif sumOutputLayer:\n",
        "        sumLayer = keras.layers.Dense(DIM+1, activation = 'linear', use_bias = False)\n",
        "        sumLayer.trainable = False\n",
        "\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = sumLayer(predPower))\n",
        "        sumLayer.set_weights([np.hstack((np.identity(DIM), np.ones((DIM,1))))])\n",
        "    else:\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = predPower)\n",
        "\n",
        "    #opt = keras.optimizers.Nadam()\n",
        "    opt = keras.optimizers.Adam()\n",
        "\n",
        "    if trainOnObj:\n",
        "        #model.compile(opt, loss=rel_mse)\n",
        "        model.compile(opt, loss=lambda x, y: perm_loss(x, y, model=model, layer_name='perm_layer', loss_func=rel_mse))  # Permutation\n",
        "    else:\n",
        "        #model.compile(opt, loss='mean_squared_error')\n",
        "        model.compile(opt, loss=lambda x, y: perm_loss(x, y, model=model, layer_name='perm_layer', loss_func=keras.losses.mse))  # Permutation\n",
        "\n",
        "    return model\n",
        "\n",
        "def DL(layer, bs, nEpochs, dfile, savedir, wpidx, trainOnObj=False, sumOutputLayer=False, init=None):\n",
        "    assert(not (trainOnObj and sumOutputLayer))\n",
        "\n",
        "    # create result directory\n",
        "    os.makedirs(savedir, exist_ok = True)\n",
        "\n",
        "    # set filenames\n",
        "    cp_name = os.path.join(savedir, 'modelCP-wp%d.{epoch:04d}.h5' % wpidx)\n",
        "    history_name = os.path.join(savedir, 'history-wp%d.h5' % wpidx)\n",
        "    savefile = os.path.join(savedir, 'model-wp%d.h5' % wpidx)\n",
        "\n",
        "\n",
        "    # build model from WP\n",
        "    model = createModel(layer, trainOnObj, sumOutputLayer)\n",
        "\n",
        "    # and show what we did\n",
        "    model.summary()\n",
        "\n",
        "    # initialize model with random weights\n",
        "    if init is None:\n",
        "        #keras.initializers.RandomNormal()\n",
        "        pass\n",
        "    else:\n",
        "        model.load_weights(init)\n",
        "\n",
        "\n",
        "    keys = ['loss', 'acc', 'val_loss', 'val_acc']\n",
        "    class LossHistory(keras.callbacks.Callback):\n",
        "        def __init__(self, fn, overwrite = False):\n",
        "            self.fn = fn\n",
        "\n",
        "            if overwrite:\n",
        "                self.mode = 'w'\n",
        "            else:\n",
        "                self.mode = 'w-'\n",
        "\n",
        "        def on_train_begin(self, logs={}):\n",
        "            with h5py.File(self.fn, self.mode) as f:\n",
        "                print('Saving history to {}'.format(self.fn))\n",
        "\n",
        "                f.create_dataset('runtime', (self.params['epochs'],))\n",
        "\n",
        "                for k in keys:\n",
        "                    f.create_dataset(k, (self.params['epochs'],), fillvalue = np.nan)\n",
        "\n",
        "        def on_epoch_begin(self, epoch, logs={}):\n",
        "            self.tic = timeit.default_timer()\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            rt = timeit.default_timer() - self.tic\n",
        "\n",
        "            with h5py.File(self.fn, 'a') as f:\n",
        "                f['runtime'][epoch] = rt\n",
        "\n",
        "                for k in keys:\n",
        "                    try:\n",
        "                        f[k][epoch] = logs[k]\n",
        "                    except KeyError:\n",
        "                        pass\n",
        "\n",
        "    hist = LossHistory(history_name, True)\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(cp_name, verbose=1, save_best_only=False, period=1)#, period=1000)\n",
        "\n",
        "    with h5py.File(dfile, 'r') as f:\n",
        "        tin = f['training/input'][...]\n",
        "        vin = f['validation/input'][...]\n",
        "\n",
        "        if trainOnObj:\n",
        "            tout = f['training/objval'][...]\n",
        "            vout = f['validation/objval'][...]\n",
        "        elif sumOutputLayer:\n",
        "            tout = f['training/xopt'][...]\n",
        "            tout = np.hstack((tout, np.sum(tout,axis=1)[:,np.newaxis]))\n",
        "            vout = f['validation/xopt'][...]\n",
        "            vout = np.hstack((vout, np.sum(vout,axis=1)[:,np.newaxis]))\n",
        "        else:\n",
        "            tout = f['training/xopt'][...]\n",
        "            vout = f['validation/xopt'][...]\n",
        "\n",
        "    history = model.fit(tin, tout, validation_data=None, epochs=nEpochs, batch_size=bs, callbacks=[hist, checkpointer])\n",
        "    model.save(savefile)\n",
        "\n",
        "    rusage = resource.getrusage(resource.RUSAGE_SELF)\n",
        "    print(rusage)\n",
        "    print('Max RAM usage: {} MB'.format(rusage.ru_maxrss/1024))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    dfile = 'dsetAZ.h5'\n",
        "    savedir = 'AZ'\n",
        "\n",
        "    layer = ([128, 64, 32, 16, 8], ['elu', 'relu', 'elu', 'relu', 'elu'])\n",
        "    nEpochs = 100\n",
        "\n",
        "    DL(layer, 128, nEpochs, dfile, savedir, 0, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "\"\"\"Evaluate model against baseline\"\"\"\n",
        "\n",
        "# Copyright (C) 2018 Bho Matthiesen\n",
        "#\n",
        "# This program is used in the article:\n",
        "#\n",
        "# Bho Matthiesen, Alessio Zappone, Eduard A. Jorswieck, and Merouane Debbah,\n",
        "# \"Deep Learning for Optimal Energy-Efficient Power Control in Wireless\n",
        "# Interference Networks,\" submitted to IEEE Journal on Selected Areas in\n",
        "# Communication.\n",
        "#\n",
        "# License:\n",
        "# This program is licensed under the GPLv2 license. If you in any way use this\n",
        "# code for research that results in publications, please cite our original\n",
        "# article listed above.\n",
        "#\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import dl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os.path\n",
        "\n",
        "dfn = '../../data/dset4.h5'\n",
        "rfn = '../../data/wsee4-processed.h5'\n",
        "rdb = '../../results/final'\n",
        "rdn = ['128', '32', '16']\n",
        "hbn = 'history-wp{wpidx}.h5'\n",
        "mbn = 'model-wp{wpidx}.h5'\n",
        "lbn = 'loss-wp{wpidx}.h5'\n",
        "tbn = 'tloss-wp{wpidx}.h5'\n",
        "\n",
        "nwp = 10\n",
        "\n",
        "mu = 4\n",
        "Pc = 1\n",
        "B = 180e3\n",
        "\n",
        "scale = 1e-6 * B * np.log2(np.e) # convert to Mbit\n",
        "\n",
        "import statsmodels.api as sm\n",
        "def ecdf(data, logtransform = True):\n",
        "    if logtransform:\n",
        "        edges = 10**np.histogram_bin_edges(np.log10(data), bins='auto')\n",
        "    else:\n",
        "        edges = np.histogram_bin_edges(data, bins='auto')\n",
        "\n",
        "    cdf = sm.distributions.ECDF(data)\n",
        "\n",
        "    return (edges, cdf(edges))\n",
        "\n",
        "def wsee_pmax(hin):\n",
        "    h = 10**np.asarray(hin[:,:-1],dtype=float).reshape(hin.shape[0], 4, 4)\n",
        "    p = 10**np.asarray(hin[:,-1], dtype=float)\n",
        "\n",
        "    direct = np.diagonal(h, axis1=1, axis2=2)\n",
        "    ifn = 1+np.sum(h,axis=2)-direct\n",
        "    rates = np.log(1+direct/ifn)\n",
        "    ee = rates/(mu*p[:,np.newaxis]+Pc)\n",
        "    wsee = np.sum(ee, axis=-1)\n",
        "\n",
        "    return wsee\n",
        "\n",
        "def wsee_best(hin):\n",
        "    h = 10**np.asarray(hin[:,:-1],dtype=float).reshape(hin.shape[0], 4, 4)\n",
        "    p = 10**np.asarray(hin[:,-1], dtype=float)\n",
        "\n",
        "    direct = np.diagonal(h, axis1=1, axis2=2)\n",
        "    best = np.max(direct, axis=-1)\n",
        "\n",
        "    rates = np.log(1+best)\n",
        "    ee = rates/(mu*p+Pc)\n",
        "\n",
        "    return ee\n",
        "\n",
        "def predict(model, inp):\n",
        "    pred = np.asarray(model.predict(inp), dtype=np.float)\n",
        "    predlin = K.clip(tf.Variable(10**pred), 0, 1)\n",
        "    Pmax = 10**np.array(inp[:,-1])\n",
        "    obj = K.eval(dl.calcObjective([tf.Variable(10**np.asarray(inp, dtype=np.float)), predlin]))\n",
        "\n",
        "    \"\"\"\n",
        "    if obj.shape[0] % PdB.shape[0] != 0:\n",
        "        N = obj.shape[0] - obj.shape[0] % PdB.shape[0]\n",
        "        obj = obj[:N]\n",
        "    else:\n",
        "        N = obj.shape[0]\n",
        "    \"\"\"\n",
        "\n",
        "    return obj\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    def reshape(d):\n",
        "        return np.nanmean(scale * d.reshape(int(d.shape[0]/len(PdB)), len(PdB)), axis=0)\n",
        "\n",
        "    with h5py.File(rfn, 'r') as f:\n",
        "        PdB = f['input/PdB'][...]\n",
        "        wsee = pd.DataFrame(index=PdB)\n",
        "\n",
        "    for r in rdn:\n",
        "        rd = rdb + r\n",
        "\n",
        "        with h5py.File(dfn,'r') as f:\n",
        "            hin = f['test/input'][...]\n",
        "\n",
        "            opt = f['test/objval'][...]\n",
        "\n",
        "            ann = np.full((nwp, len(PdB)), np.nan)\n",
        "            relerr = np.full((nwp, len(f['test/input'])), np.nan)\n",
        "            for i in range(nwp):\n",
        "                ANN = predict(keras.models.load_model(os.path.join(rd, mbn.format(wpidx=i))), f['test/input'][...])\n",
        "                ann[i,:] = reshape(opt)\n",
        "                relerr[i,:] = np.abs(opt - ANN) / opt # scaling is not necessary here\n",
        "\n",
        "            relerr = np.mean(relerr, axis=0)\n",
        "\n",
        "            wsee = wsee.assign(\n",
        "                    opt = reshape(opt),\n",
        "                    SCA = reshape(f['test/SCA'][...]),\n",
        "                    SCAos = reshape(f['test/SCAmax'][...]),\n",
        "                    ANN = np.mean(ann, axis=0)\n",
        "                    )\n",
        "\n",
        "            x, y = ecdf(relerr)\n",
        "            relerr2 = pd.DataFrame(index = x, data = {'y': y})\n",
        "            del y\n",
        "\n",
        "        wsee = wsee.assign(\n",
        "                max = reshape(wsee_pmax(hin)),\n",
        "                best = reshape(wsee_best(hin))\n",
        "                )\n",
        "\n",
        "        # collect losses\n",
        "        loss = None\n",
        "        val_loss = None\n",
        "        for i in range(nwp):\n",
        "            with h5py.File(os.path.join(rd, tbn.format(wpidx=i)), 'r') as f:\n",
        "                if loss is None:\n",
        "                    loss = np.full((nwp, f['training_loss'].shape[0]), np.nan)\n",
        "                    val_loss = loss.copy()\n",
        "\n",
        "                loss[i] = f['training_loss'][:]\n",
        "\n",
        "            with h5py.File(os.path.join(rd, lbn.format(wpidx=i)), 'r') as f:\n",
        "                val_loss[i] = f['loss'][:]\n",
        "\n",
        "        loss = pd.DataFrame(data = {'loss': np.mean(loss, axis=0), 'val_loss': np.mean(val_loss, axis=0)})\n",
        "        loss.index += 1\n",
        "        del val_loss\n",
        "\n",
        "\n",
        "        # save\n",
        "        wsee.to_csv('../tex/verification_%s.dat' % r, index_label = 'snr')\n",
        "        relerr2.to_csv('../tex/verification_relerr_%s.dat' % r, index_label = 'x')\n",
        "        loss.to_csv('../tex/training_%s.dat' % r, index_label = 'epoch')\n",
        "\n",
        "        #wsee.plot()\n",
        "        #plt.show()"
      ],
      "metadata": {
        "id": "3QJ4UO9dEMb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}