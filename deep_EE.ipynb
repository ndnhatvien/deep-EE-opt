{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7WsIumNz4aom/+wgo7eNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndnhatvien/deep-EE-opt/blob/master/deep_EE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1fYO7DU-lom"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# Copyright (C) 2018-2020 Bho Matthiesen, Karl-Ludwig Besser\n",
        "#\n",
        "# This program is used in the article:\n",
        "#\n",
        "# Bho Matthiesen, Alessio Zappone, Karl-L. Besser, Eduard A. Jorswieck, and\n",
        "# Merouane Debbah, \"A Globally Optimal Energy-Efficient Power Control Framework\n",
        "# and its Efficient Implementation in Wireless Interference Networks,\"\n",
        "# submitted to IEEE Transactions on Signal Processing\n",
        "#\n",
        "# License:\n",
        "# This program is licensed under the GPLv2 license. If you in any way use this\n",
        "# code for research that results in publications, please cite our original\n",
        "# article listed above.\n",
        "#\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU General Public License for more details.\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools as it\n",
        "import h5py\n",
        "import os\n",
        "import os.path\n",
        "import resource\n",
        "import timeit\n",
        "\n",
        "class IndexPermutationLayer(keras.layers.Layer):\n",
        "    def __init__(self, permutations=None, **kwargs):\n",
        "        if permutations is None:\n",
        "            permutations = list(it.permutations(range(DIM)))\n",
        "        self.permutations = K.constant(permutations, 'int32')\n",
        "        self.num_perms, self.num_ue = np.shape(permutations)\n",
        "        self.perm = 0\n",
        "        super(IndexPermutationLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        def permute_users():\n",
        "            _perm = K.random_uniform((1,), 0, self.num_perms, dtype='int32')\n",
        "            perm = self.permutations[_perm[0], :]\n",
        "            self.perm = perm\n",
        "            t = K.tile(perm, self.num_ue)\n",
        "            r = K.repeat_elements(perm, self.num_ue, 0)\n",
        "            perm_idx = self.num_ue*r + t\n",
        "            self.perm_idx = K.concatenate((perm_idx, K.constant([self.num_ue**2], 'int32')))\n",
        "            P = tf.gather(x, self.perm_idx, axis=-1)\n",
        "            return P\n",
        "        return K.in_train_phase(permute_users, x, training=training)\n",
        "\n",
        "def perm_loss(y_true, y_pred, model=None, layer_name='perm_layer', loss_func=keras.losses.mse):\n",
        "    #training = K.learning_phase()\n",
        "    #if training == 1 or training is True:\n",
        "    #    _perm = model.get_layer(layer_name).perm#_idx\n",
        "    #    y_true = tf.gather(y_true, _perm, axis=-1)\n",
        "    _perm = model.get_layer(layer_name).perm#_idx\n",
        "    y_true = tf.gather(y_true, _perm, axis=-1)\n",
        "    return loss_func(y_true, y_pred)\n",
        "\n",
        "def rel_mse(x_true, x_pred):\n",
        "    loss = K.square(K.abs((x_true - x_pred)/ x_true))\n",
        "    return K.mean(loss, axis=-1)\n",
        "\n",
        "DIM = 4\n",
        "mu = 4\n",
        "Pc = 1\n",
        "\n",
        "def calcObjective(tensors):\n",
        "    h = keras.layers.Reshape((DIM,DIM))(tensors[0][:,:-1])\n",
        "    mmu = mu * tensors[0][:,-1]\n",
        "    x = keras.layers.Activation('relu')(tensors[1])\n",
        "\n",
        "    o = keras.layers.multiply([h,x])\n",
        "    alpha = tf.matrix_diag_part(o)\n",
        "    beta = 1 + (K.sum(o, axis=-1) - alpha)\n",
        "\n",
        "    rate = K.log(1 + alpha/beta)\n",
        "    ret = K.sum(rate / (keras.layers.multiply([mmu, x]) + Pc), axis=-1)\n",
        "    #ret = tf.Print(ret, [ret])\n",
        "    #ret = K.sum(rate, axis=-1)\n",
        "    return ret\n",
        "\n",
        "def calcObjectivePow(tensors):\n",
        "    ten = tf.constant(10, dtype=tensors[0].dtype)\n",
        "\n",
        "    h = tf.pow(ten, tensors[0])\n",
        "    x = tf.pow(ten, tensors[1])\n",
        "\n",
        "    return calcObjective([h, x])\n",
        "\n",
        "def createModel(layer, trainOnObj, sumOutputLayer = False):\n",
        "    from dl import calcObjective, calcObjectivePow, rel_mse\n",
        "\n",
        "    inlayer = keras.layers.Input(shape = (DIM**2+1,))\n",
        "\n",
        "    x = inlayer\n",
        "    __permutations = list(it.permutations(range(DIM)))\n",
        "    x = IndexPermutationLayer(__permutations, name=\"perm_layer\")(x)\n",
        "    for n, a in zip(*layer):\n",
        "        x = keras.layers.Dense(n, activation = a)(x)\n",
        "    predPower = keras.layers.Dense(DIM, activation = 'linear')(x)\n",
        "\n",
        "    assert(not (trainOnObj and sumOutputLayer))\n",
        "\n",
        "    if trainOnObj:\n",
        "        objlayer = keras.layers.Lambda(calcObjectivePow, (1,))([inlayer, predPower])\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = objlayer)\n",
        "    elif sumOutputLayer:\n",
        "        sumLayer = keras.layers.Dense(DIM+1, activation = 'linear', use_bias = False)\n",
        "        sumLayer.trainable = False\n",
        "\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = sumLayer(predPower))\n",
        "        sumLayer.set_weights([np.hstack((np.identity(DIM), np.ones((DIM,1))))])\n",
        "    else:\n",
        "        model = keras.models.Model(inputs = inlayer, outputs = predPower)\n",
        "\n",
        "    #opt = keras.optimizers.Nadam()\n",
        "    opt = keras.optimizers.Adam()\n",
        "\n",
        "    if trainOnObj:\n",
        "        #model.compile(opt, loss=rel_mse)\n",
        "        model.compile(opt, loss=lambda x, y: perm_loss(x, y, model=model, layer_name='perm_layer', loss_func=rel_mse))  # Permutation\n",
        "    else:\n",
        "        #model.compile(opt, loss='mean_squared_error')\n",
        "        model.compile(opt, loss=lambda x, y: perm_loss(x, y, model=model, layer_name='perm_layer', loss_func=keras.losses.mse))  # Permutation\n",
        "\n",
        "    return model\n",
        "\n",
        "def DL(layer, bs, nEpochs, dfile, savedir, wpidx, trainOnObj=False, sumOutputLayer=False, init=None):\n",
        "    assert(not (trainOnObj and sumOutputLayer))\n",
        "\n",
        "    # create result directory\n",
        "    os.makedirs(savedir, exist_ok = True)\n",
        "\n",
        "    # set filenames\n",
        "    cp_name = os.path.join(savedir, 'modelCP-wp%d.{epoch:04d}.h5' % wpidx)\n",
        "    history_name = os.path.join(savedir, 'history-wp%d.h5' % wpidx)\n",
        "    savefile = os.path.join(savedir, 'model-wp%d.h5' % wpidx)\n",
        "\n",
        "\n",
        "    # build model from WP\n",
        "    model = createModel(layer, trainOnObj, sumOutputLayer)\n",
        "\n",
        "    # and show what we did\n",
        "    model.summary()\n",
        "\n",
        "    # initialize model with random weights\n",
        "    if init is None:\n",
        "        #keras.initializers.RandomNormal()\n",
        "        pass\n",
        "    else:\n",
        "        model.load_weights(init)\n",
        "\n",
        "\n",
        "    keys = ['loss', 'acc', 'val_loss', 'val_acc']\n",
        "    class LossHistory(keras.callbacks.Callback):\n",
        "        def __init__(self, fn, overwrite = False):\n",
        "            self.fn = fn\n",
        "\n",
        "            if overwrite:\n",
        "                self.mode = 'w'\n",
        "            else:\n",
        "                self.mode = 'w-'\n",
        "\n",
        "        def on_train_begin(self, logs={}):\n",
        "            with h5py.File(self.fn, self.mode) as f:\n",
        "                print('Saving history to {}'.format(self.fn))\n",
        "\n",
        "                f.create_dataset('runtime', (self.params['epochs'],))\n",
        "\n",
        "                for k in keys:\n",
        "                    f.create_dataset(k, (self.params['epochs'],), fillvalue = np.nan)\n",
        "\n",
        "        def on_epoch_begin(self, epoch, logs={}):\n",
        "            self.tic = timeit.default_timer()\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            rt = timeit.default_timer() - self.tic\n",
        "\n",
        "            with h5py.File(self.fn, 'a') as f:\n",
        "                f['runtime'][epoch] = rt\n",
        "\n",
        "                for k in keys:\n",
        "                    try:\n",
        "                        f[k][epoch] = logs[k]\n",
        "                    except KeyError:\n",
        "                        pass\n",
        "\n",
        "    hist = LossHistory(history_name, True)\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(cp_name, verbose=1, save_best_only=False, period=1)#, period=1000)\n",
        "\n",
        "    with h5py.File(dfile, 'r') as f:\n",
        "        tin = f['training/input'][...]\n",
        "        vin = f['validation/input'][...]\n",
        "\n",
        "        if trainOnObj:\n",
        "            tout = f['training/objval'][...]\n",
        "            vout = f['validation/objval'][...]\n",
        "        elif sumOutputLayer:\n",
        "            tout = f['training/xopt'][...]\n",
        "            tout = np.hstack((tout, np.sum(tout,axis=1)[:,np.newaxis]))\n",
        "            vout = f['validation/xopt'][...]\n",
        "            vout = np.hstack((vout, np.sum(vout,axis=1)[:,np.newaxis]))\n",
        "        else:\n",
        "            tout = f['training/xopt'][...]\n",
        "            vout = f['validation/xopt'][...]\n",
        "\n",
        "    history = model.fit(tin, tout, validation_data=None, epochs=nEpochs, batch_size=bs, callbacks=[hist, checkpointer])\n",
        "    model.save(savefile)\n",
        "\n",
        "    rusage = resource.getrusage(resource.RUSAGE_SELF)\n",
        "    print(rusage)\n",
        "    print('Max RAM usage: {} MB'.format(rusage.ru_maxrss/1024))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    dfile = 'dsetAZ.h5'\n",
        "    savedir = 'AZ'\n",
        "\n",
        "    layer = ([128, 64, 32, 16, 8], ['elu', 'relu', 'elu', 'relu', 'elu'])\n",
        "    nEpochs = 100\n",
        "\n",
        "    DL(layer, 128, nEpochs, dfile, savedir, 0, False)"
      ]
    }
  ]
}